{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Tweets\n",
    "\n",
    "Donwload and save tweets, using a **query** value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "env_path = Path('../.env').resolve()\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API access\n",
    "\n",
    "First of all, we'll connect to the Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = os.getenv(\"CONSUMER_KEY\")\n",
    "consumer_secret = os.getenv(\"CONSUMER_SECRET\")\n",
    "access_token = os.getenv(\"ACCESS_TOKEN\")\n",
    "access_token_secret = os.getenv(\"ACCESS_TOKEN_SECRET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import OAuthHandler, API, TweepError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to the Twitter API.\n"
     ]
    }
   ],
   "source": [
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = API(auth)\n",
    "print('Successfully connected to the Twitter API.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Tweets\n",
    "\n",
    "Now we can define our query and search for the tweets containing it.\n",
    "\n",
    "- **query**: *hashtag* or *emoji* that will be used to fetch the tweets\n",
    "- **max_requests**: Maximum number of requests to the API.\n",
    "    - Restriction: 180 requests / 15 min window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '#angry'\n",
    "max_requests = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts aliases to the real emoji representation (e.g. :thumbs_up: => üëç)\n",
    "\n",
    "from emoji import emojize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = emojize(query) + ' -filter:retweets'\n",
    "searched_tweets = []\n",
    "last_id = -1\n",
    "request_count = 0\n",
    "while request_count < max_requests:\n",
    "    try:\n",
    "        new_tweets = api.search(q=q,\n",
    "                                lang='en',\n",
    "                                count=100,\n",
    "                                max_id=str(last_id - 1),\n",
    "                                tweet_mode='extended')\n",
    "        if not new_tweets:\n",
    "            break\n",
    "        searched_tweets.extend(new_tweets)\n",
    "        last_id = new_tweets[-1].id\n",
    "        request_count += 1\n",
    "    except TweepError as e:\n",
    "        print(e)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format and save\n",
    "\n",
    "Format the API data to the desired structure and save a `.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 #angry tweets\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for tweet in searched_tweets:\n",
    "    data.append([tweet.id, tweet.created_at, tweet.user.screen_name, tweet.full_text])\n",
    "df = pd.DataFrame(data=data, columns=['id', 'date', 'user', 'text'])\n",
    "print(str(len(data)) + ' ' + query + ' tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1151133382627057664</td>\n",
       "      <td>2019-07-16 14:16:00</td>\n",
       "      <td>DaradeAbhijeet</td>\n",
       "      <td>Don't promise when you are #Happy\\n&amp;amp;\\nDon'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1151124672496324608</td>\n",
       "      <td>2019-07-16 13:41:23</td>\n",
       "      <td>TheRealFakeJack</td>\n",
       "      <td>@realDonaldTrump 4:20 am it is a sign u need t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1151118984793776129</td>\n",
       "      <td>2019-07-16 13:18:47</td>\n",
       "      <td>masterofnaps</td>\n",
       "      <td>There's a special place in hell for people who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1151115966220328960</td>\n",
       "      <td>2019-07-16 13:06:47</td>\n",
       "      <td>TiknisArts</td>\n",
       "      <td>We know #Trump needs #attention to survive. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1151113082099232768</td>\n",
       "      <td>2019-07-16 12:55:20</td>\n",
       "      <td>emilieraddish</td>\n",
       "      <td>Get your Instagram photo elsewhere not on top ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                date             user  \\\n",
       "0  1151133382627057664 2019-07-16 14:16:00   DaradeAbhijeet   \n",
       "1  1151124672496324608 2019-07-16 13:41:23  TheRealFakeJack   \n",
       "2  1151118984793776129 2019-07-16 13:18:47     masterofnaps   \n",
       "3  1151115966220328960 2019-07-16 13:06:47       TiknisArts   \n",
       "4  1151113082099232768 2019-07-16 12:55:20    emilieraddish   \n",
       "\n",
       "                                                text  \n",
       "0  Don't promise when you are #Happy\\n&amp;\\nDon'...  \n",
       "1  @realDonaldTrump 4:20 am it is a sign u need t...  \n",
       "2  There's a special place in hell for people who...  \n",
       "3  We know #Trump needs #attention to survive. It...  \n",
       "4  Get your Instagram photo elsewhere not on top ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved under: \"/home/rmohashi/Workspace/emotion-from-tweets/datasets/tweepy\"\n"
     ]
    }
   ],
   "source": [
    "PATH = Path('../datasets/tweepy').resolve()\n",
    "filename = query + '.csv'\n",
    "df.to_csv(os.path.join(PATH, filename), index=None)\n",
    "print('Saved under: \"' + PATH.as_posix() + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
