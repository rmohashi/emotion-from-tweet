{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Emotion\n",
    "\n",
    "The main objective of this notebook is to predict emotions from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project path to the PYTHONPATH\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(Path(os.path.join(os.path.abspath(''), '../')).resolve().as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokenizer\n",
    "\n",
    "Load `.pickle` file with the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = Path('../datasets/sentiment_analysis/tokenizer.pickle').resolve()\n",
    "with tokenizer_path.open('rb') as file:\n",
    "    tokenizer = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "Load the trained emotion recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, SpatialDropout1D, LSTM\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Bidirectional, Conv1D, Dense, concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = min(tokenizer.num_words, len(tokenizer.word_index) + 1)\n",
    "num_classes = 4\n",
    "embedding_dim = 500\n",
    "input_length = 100\n",
    "lstm_units = 128\n",
    "lstm_dropout = 0.1\n",
    "recurrent_dropout = 0.1\n",
    "spatial_dropout=0.2\n",
    "filters=64\n",
    "kernel_size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0719 10:47:51.968286 4693956032 deprecation.py:506] From /Users/rmohashi/miniconda3/envs/emodata/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0719 10:47:52.031774 4693956032 deprecation.py:506] From /Users/rmohashi/miniconda3/envs/emodata/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0719 10:47:52.039301 4693956032 deprecation.py:506] From /Users/rmohashi/miniconda3/envs/emodata/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0719 10:47:52.040482 4693956032 deprecation.py:506] From /Users/rmohashi/miniconda3/envs/emodata/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0719 10:47:52.041715 4693956032 deprecation.py:506] From /Users/rmohashi/miniconda3/envs/emodata/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(input_length,))\n",
    "output_layer = Embedding(\n",
    "  input_dim=input_dim,\n",
    "  output_dim=embedding_dim,\n",
    "  input_shape=(input_length,)\n",
    ")(input_layer)\n",
    "\n",
    "output_layer = SpatialDropout1D(spatial_dropout)(output_layer)\n",
    "\n",
    "output_layer = Bidirectional(\n",
    "LSTM(lstm_units, return_sequences=True,\n",
    "     dropout=lstm_dropout, recurrent_dropout=recurrent_dropout)\n",
    ")(output_layer)\n",
    "output_layer = Conv1D(filters, kernel_size=kernel_size, padding='valid',\n",
    "                    kernel_initializer='glorot_uniform')(output_layer)\n",
    "\n",
    "avg_pool = GlobalAveragePooling1D()(output_layer)\n",
    "max_pool = GlobalMaxPooling1D()(output_layer)\n",
    "output_layer = concatenate([avg_pool, max_pool])\n",
    "\n",
    "output_layer = Dense(num_classes, activation='softmax')(output_layer)\n",
    "\n",
    "model = Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_path = Path('../models/emotion_recognition/model_weights.h5').resolve()\n",
    "model.load_weights(model_weights_path.as_posix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Load the data that will have the labels predicted by the model\n",
    "\n",
    "**data_path**: Path to the `.csv` file that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1151893341782585349</td>\n",
       "      <td>2019-07-18 16:35:48</td>\n",
       "      <td>Ozzzylot</td>\n",
       "      <td>⚡️ Fans share what Kyoto Animation studio mean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1151893322908102657</td>\n",
       "      <td>2019-07-18 16:35:43</td>\n",
       "      <td>rosyutori</td>\n",
       "      <td>Deep condolences to all who are passed away at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1151893318101377024</td>\n",
       "      <td>2019-07-18 16:35:42</td>\n",
       "      <td>met_bit</td>\n",
       "      <td>Striking news... How on earth can someone be s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1151893304117813248</td>\n",
       "      <td>2019-07-18 16:35:39</td>\n",
       "      <td>Destructo_Dan</td>\n",
       "      <td>I don’t know if I had any favorite anime from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1151893302863650816</td>\n",
       "      <td>2019-07-18 16:35:39</td>\n",
       "      <td>KDiscavage</td>\n",
       "      <td>The news about Kyoto Animation Studios hit me ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                 date           user  \\\n",
       "0  1151893341782585349  2019-07-18 16:35:48       Ozzzylot   \n",
       "1  1151893322908102657  2019-07-18 16:35:43      rosyutori   \n",
       "2  1151893318101377024  2019-07-18 16:35:42        met_bit   \n",
       "3  1151893304117813248  2019-07-18 16:35:39  Destructo_Dan   \n",
       "4  1151893302863650816  2019-07-18 16:35:39     KDiscavage   \n",
       "\n",
       "                                                text  \n",
       "0  ⚡️ Fans share what Kyoto Animation studio mean...  \n",
       "1  Deep condolences to all who are passed away at...  \n",
       "2  Striking news... How on earth can someone be s...  \n",
       "3  I don’t know if I had any favorite anime from ...  \n",
       "4  The news about Kyoto Animation Studios hit me ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path('../datasets/predict/1151893341782585349-1151863653320159233_kyoto_animation.csv').resolve()\n",
    "data = pd.read_csv(data_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Encoder\n",
    "\n",
    "Load `.pickle` file with the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_path = Path('../models/emotion_recognition/encoder.pickle').resolve()\n",
    "with encoder_path.open('rb') as file:\n",
    "    encoder = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "Preprocess the data that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rmohashi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nlp import preprocess\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean up: 1.41 sec\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = preprocess(data.text)\n",
    "sequences = [text.split() for text in cleaned_data]\n",
    "list_tokenized = tokenizer.texts_to_sequences(sequences)\n",
    "x_data = pad_sequences(list_tokenized, maxlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Predict the labels and generate a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry: 0.0977998\n",
      "fear: 0.3991122\n",
      "joy: 0.03104621\n",
      "sadness: 0.4720413\n"
     ]
    }
   ],
   "source": [
    "for index, value in enumerate(np.sum(y_pred, axis=0) / len(y_pred)):\n",
    "    print(encoder.classes_[index] + \": \" + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry: 0.09889558232931726\n",
      "fear: 0.4011044176706827\n",
      "joy: 0.030622489959839357\n",
      "sadness: 0.46937751004016065\n"
     ]
    }
   ],
   "source": [
    "y_pred_argmax = y_pred.argmax(axis=1)\n",
    "data_len = len(y_pred_argmax)\n",
    "for index, value in enumerate(np.unique(y_pred_argmax)):\n",
    "    print(encoder.classes_[index] + \": \" + str(len(y_pred_argmax[y_pred_argmax == value]) / data_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[5:10].argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My heart goes out to the people who died in the fire at Kyoto Animation Studio. \\n\\n#PrayForKyoani https://t.co/Jvg9R8f6Oc'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text.iloc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
